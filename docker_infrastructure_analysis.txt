# MindCare Docker Infrastructure - Complete Analysis

## Overview
The MindCare project uses Docker and Docker Compose to create a containerized, scalable infrastructure specifically optimized for AI-powered mental health applications with GPU acceleration and secure data handling.

## Docker Container Architecture

### Container Stack Overview
```
┌─────────────────────────────────────────────────────────────────┐
│                    DOCKER DEPLOYMENT STACK                     │
└─────────────────────────────────────────────────────────────────┘

┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Web Container │    │  Ollama (GPU)   │    │   PostgreSQL    │
│                 │    │   Container     │    │   + pgvector    │
│ - Django App    │◄──►│                 │    │                 │
│ - REST APIs     │    │ - AI Models     │    │ - User Data     │
│ - RAG System    │    │ - Embeddings    │    │ - Vector Store  │
│ - Port: 8000    │    │ - Port: 11434   │    │ - Port: 5432    │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

## Docker Configuration Files

### 1. Main Application Container (docker-compose.yml)
```yaml
version: '3.8'

services:
  web:
    build: .           # Uses main Dockerfile
    ports:
      - "8000:8000"    # Django development server
    environment:
      - ALLOWED_HOSTS=*
      - DJANGO_ENV=development
    volumes:
      - .:/app         # Live code reload during development
    command: >
      sh -c "python manage.py migrate &&
             python manage.py runserver 0.0.0.0:8000"
```

**Purpose**: Main Django application container for development with live code reloading.

### 2. GPU-Accelerated AI Container (docker-compose.gpu.yml)
```yaml
version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - OLLAMA_NUM_GPU=50    # GPU layers for AI processing
    ports:
      - "11434:11434"        # Ollama API port
    volumes:
      - ollama:/root/.ollama

volumes:
  ollama:
```

**Purpose**: Dedicated container for AI model processing with GPU acceleration for RAG pipeline.

### 3. Main Application Dockerfile
```dockerfile
FROM python:3.11-slim as base

ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=off \
    PIP_DISABLE_PIP_VERSION_CHECK=on

# Security: Non-root user
RUN groupadd -r django && useradd -r -g django django

WORKDIR /app

# System dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    libpq-dev \
    postgresql-client \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Python dependencies
COPY requirements.txt /app/
RUN pip install --upgrade pip && pip install -r requirements.txt

# Application code
COPY --chown=django:django . /app/

# Production static files
RUN if [ "$DJANGO_ENV" = "production" ]; then python manage.py collectstatic --noinput; fi

USER django
EXPOSE 8000

# Health monitoring
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health/ || exit 1

CMD ["sh", "-c", "python manage.py migrate && python manage.py runserver 0.0.0.0:8000"]
```

### 4. PostgreSQL with Vector Extensions (pgvector/Dockerfile)
```dockerfile
ARG PG_MAJOR=15
FROM postgres:$PG_MAJOR
ARG PG_MAJOR

COPY . /tmp/pgvector

RUN apt-get update && \
    apt-mark hold locales && \
    apt-get install -y --no-install-recommends build-essential postgresql-server-dev-$PG_MAJOR && \
    cd /tmp/pgvector && \
    make clean && \
    make OPTFLAGS="" && \
    make install && \
    mkdir /usr/share/doc/pgvector && \
    cp LICENSE README.md /usr/share/doc/pgvector && \
    rm -r /tmp/pgvector && \
    apt-get remove -y build-essential postgresql-server-dev-$PG_MAJOR && \
    apt-get autoremove -y && \
    apt-mark unhold locales && \
    rm -rf /var/lib/apt/lists/*
```

**Purpose**: Custom PostgreSQL container with pgvector extension for similarity search in RAG system.

## Container Use Cases

### 1. Development Environment
```bash
# Basic development (CPU only)
docker-compose up --build

# GPU-accelerated development (with AI models)
docker-compose -f docker-compose.yml -f docker-compose.gpu.yml up --build

# Stop all containers
docker stop $(docker ps -q)
```

### 2. AI/RAG Processing Container (Ollama)
**Functions**:
- Text embeddings generation (`nomic-embed-text:latest`)
- Therapy approach classification
- GPU acceleration for RAG pipeline
- Crisis detection AI processing
- Real-time query embedding

**GPU Configuration**:
```python
# Auto-detects and configures GPU usage
OLLAMA_NUM_GPU = 50  # Default GPU layers

# Scales based on available GPU memory:
# - >8GB RAM: 99 layers (maximum performance)
# - >6GB RAM: 75 layers 
# - >4GB RAM: 50 layers
# - >2GB RAM: 35 layers
# - <2GB RAM: CPU only mode
```

### 3. Database Container with Vector Search
**Functions**:
- Similarity search for RAG system
- Storing therapy document embeddings (768-dimensional vectors)
- User data storage with vector operations
- Mental health data with HIPAA compliance
- Support for cosine similarity computations

## Integration with MindCare Architecture

### RAG Pipeline Container Flow
```
PDF Documents → Docker Container Processing → Vector Storage
     ↓
Text Chunking → Ollama Container (Embeddings) → pgvector DB
     ↓
User Queries → Django Container → AI Analysis → Therapy Response
```

### Mental Health Data Flow
```
Patient App → Django Container → AI Processing → Crisis Detection
     ↓              ↓                ↓              ↓
Data Storage → Analytics → Therapy RAG → Emergency Alerts
```

### Multi-Container Communication
```
┌─────────────────┐     HTTP/API     ┌─────────────────┐
│   Django Web    │◄───────────────►│   Ollama AI     │
│   Container     │                 │   Container     │
│                 │                 │                 │
│ - Chatbot API   │                 │ - Embeddings    │
│ - User Auth     │                 │ - Text Analysis │
│ - RAG Service   │                 │ - GPU Accel     │
└─────────┬───────┘                 └─────────────────┘
          │                                   │
          │ PostgreSQL                       │
          │ Connection                       │
          ▼                                   ▼
┌─────────────────┐                 ┌─────────────────┐
│   PostgreSQL    │                 │   File System   │
│   + pgvector    │                 │                 │
│                 │                 │ - Vector Cache  │
│ - User Data     │                 │ - Model Storage │
│ - Vector Store  │                 │ - Embeddings    │
│ - HIPAA Data    │                 │ - Documents     │
└─────────────────┘                 └─────────────────┘
```

## Performance Optimization Features

### 1. GPU Acceleration
- **NVIDIA GPU Support**: Automatic detection and configuration
- **CUDA Integration**: GPU-accelerated embedding generation
- **Memory Management**: Dynamic GPU layer allocation
- **Fallback**: Graceful degradation to CPU if GPU unavailable

### 2. Security Features
```dockerfile
# Non-root user for security
RUN groupadd -r django && useradd -r -g django django
USER django

# Minimal attack surface
FROM python:3.11-slim

# Health monitoring
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3
```

### 3. Development Features
- **Live Code Reload**: Volume mounting for development
- **Environment Variables**: Configuration through environment
- **Multi-Environment Support**: Development/Production configurations
- **Debugging Support**: Port exposure for debugging tools

## Production Deployment Features

### 1. Scalability
- **Horizontal Scaling**: Multiple container instances
- **Load Balancing**: Container orchestration ready
- **Resource Limits**: Memory and CPU constraints
- **Auto-restart**: Container health monitoring

### 2. Data Persistence
```yaml
volumes:
  - postgres_data:/var/lib/postgresql/data
  - ollama_models:/root/.ollama
  - static_files:/app/staticfiles
  - media_files:/app/media
```

### 3. Security & Compliance
- **HIPAA Compliance**: Isolated containers for sensitive health data
- **Network Isolation**: Container-to-container communication only
- **Encrypted Storage**: Volume encryption support
- **Audit Logging**: Container activity monitoring

## Mental Health Specific Features

### 1. Crisis Monitoring
- **Real-time Processing**: Immediate crisis detection in containers
- **Alert System**: Container-based notification services
- **Failover**: Redundant crisis detection containers

### 2. Therapy RAG System
- **Document Processing**: Containerized PDF processing
- **Vector Storage**: Isolated vector database
- **AI Models**: Dedicated AI processing container
- **Response Generation**: Therapeutic content generation

### 3. Data Privacy
- **Container Isolation**: Each service in separate containers
- **Encrypted Communication**: TLS between containers
- **Access Control**: Role-based container access
- **Data Masking**: Sensitive data protection in containers

## Command Reference

### Basic Operations
```bash
# Start development environment
docker-compose up --build

# Start with GPU support
docker-compose -f docker-compose.yml -f docker-compose.gpu.yml up --build

# Stop all containers
docker stop $(docker ps -q)

# View container logs
docker-compose logs -f web
docker-compose logs -f ollama

# Execute commands in running containers
docker-compose exec web python manage.py shell
docker-compose exec web python manage.py migrate
```

### Debugging
```bash
# Check container status
docker-compose ps

# Monitor resource usage
docker stats

# Access container shell
docker-compose exec web bash
docker-compose exec ollama bash

# View container networks
docker network ls
```

### Production Commands
```bash
# Production deployment
docker-compose -f docker-compose.prod.yml up -d

# Scale services
docker-compose up --scale web=3

# Update containers
docker-compose pull
docker-compose up -d --no-deps web
```

## Benefits for MindCare Platform

### 1. HIPAA Compliance
- **Data Isolation**: Containers ensure data separation
- **Audit Trails**: Container logging for compliance
- **Access Control**: Container-level security
- **Encryption**: Data encryption at rest and in transit

### 2. AI Performance
- **GPU Acceleration**: Optimized AI model performance
- **Resource Management**: Dedicated AI processing containers
- **Scaling**: Independent scaling of AI services
- **Caching**: Container-level model caching

### 3. Development Efficiency
- **Consistent Environment**: Same setup across all environments
- **Rapid Deployment**: Quick container startup
- **Service Isolation**: Independent service development
- **Easy Testing**: Container-based testing environments

### 4. Operational Benefits
- **Monitoring**: Container health checks and monitoring
- **Backup**: Container volume backup strategies
- **Updates**: Rolling updates without downtime
- **Debugging**: Isolated troubleshooting per service

This Docker infrastructure is specifically designed for a mental health platform requiring AI processing, data security, and scalable architecture while maintaining HIPAA compliance and optimal performance for therapeutic applications.
