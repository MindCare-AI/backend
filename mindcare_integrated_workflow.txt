# MindCare Platform - Complete Integrated Workflow
## Chatbot, AI Engine, and Datawarehouse Integration

This document outlines the complete workflow showing how the three core components work together to provide intelligent mental health support.

## Complete System Workflow

### 1. DATA COLLECTION FLOW
```
1. User Interaction Sources --> 2. Datawarehouse Collection --> 3. Data Processing
```

**Step 1: User Interaction Sources**
- Patient mood logs (mood app)
- Journal entries (journal app)  
- Chatbot conversations (chatbot app)
- Social feed interactions (feeds app)
- Therapy session notes (therapist app)
- Messaging patterns (messaging app)
- Health metrics (patient app)

**Step 2: Datawarehouse Collection Services**
- `unified_data_collection_service.py` (Main orchestrator)
- `mood_collection_service.py` (Mood tracking data)
- `journal_collection_service.py` (Journal analysis)
- `chatbot_messaging_service.py` (Chatbot interactions)
- `feeds_service.py` (Social engagement)
- `therapist_session_notes_service.py` (Session analytics)
- `messaging_collection_service.py` (Communication patterns)

**Step 3: Data Processing & Storage**
- `etl_service.py` (Extract, Transform, Load)
- `realtime_analytics.py` (Live processing)
- Storage in warehouse models (UserDataSnapshot, MoodTrendAnalysis, etc.)

### 2. AI ANALYSIS FLOW
```
4. AI Data Interface --> 5. AI Analysis Services --> 6. Insights Generation
```

**Step 4: AI Data Interface Service**
- `AI_engine/services/data_interface.py`
- `get_ai_ready_dataset()` - Fetches processed data from datawarehouse
- `get_mood_analytics()` - Mood-specific analysis
- `get_journal_analytics()` - Journal content analysis
- `get_behavioral_patterns()` - User behavior analysis

**Step 5: AI Analysis Services**
- `ai_analysis.py` - Main AI orchestrator (Uses Ollama/Mistral LLM)
- `predictive_service.py` - Mood prediction and risk assessment
- `social_analysis.py` - Social interaction patterns
- `therapy_analysis.py` - Therapy effectiveness analysis
- `conversation_summary.py` - Therapeutic conversation summaries
- `crisis_monitoring.py` - Crisis detection and intervention

**Step 6: Insights Generation & Storage**
- AI-generated insights stored in `UserAnalysis`, `AIInsight` models
- Therapy recommendations created
- Risk alerts and notifications triggered

### 3. CHATBOT INTERACTION FLOW
```
7. User Message --> 8. RAG Processing --> 9. AI Context Enhancement --> 10. Response Generation
```

**Step 7: User Message Input**
- `chatbot/views.py` - ChatbotViewSet receives user message
- `chatbot_service.py` - Main chatbot orchestrator

**Step 8: RAG (Retrieval-Augmented Generation) Processing**
- `therapy_rag_service.py` - Therapy approach recommendation
- `local_vector_store.py` - Semantic search in therapy documents
- `vector_store.py` - PostgreSQL with pgvector for CBT/DBT content
- `fallback_classifier.py` - Backup therapy classification

**Step 9: AI Context Enhancement**
- `chatbot_service._get_user_data()` - Retrieve user's journal/mood data
- `chatbot_service._get_enhanced_ai_analysis()` - Get AI insights from AI Engine
- `therapy_rag_service.get_therapy_approach()` - Get therapy recommendations
- `chatbot_service._build_prompt()` - Enhance query with user context

**Step 10: Response Generation & Crisis Detection**
- Ollama/Mistral LLM generates contextual response
- `crisis_monitoring.py` - Real-time crisis detection
- `chatbot_service._humanize_response()` - Make response natural
- Response stored back to datawarehouse for learning

## Detailed Service-to-Service Workflow

### A. USER CREATES MOOD LOG
```
1. Patient (mood app) --> 2. MoodLog.save() --> 3. unified_data_collection_service --> 4. mood_collection_service --> 5. AI analysis triggers
```

### B. USER WRITES JOURNAL ENTRY  
```
1. Patient (journal app) --> 2. JournalEntry.save() --> 3. unified_data_collection_service --> 4. journal_collection_service --> 5. AI sentiment analysis --> 6. Insights stored
```

### C. USER CHATS WITH CHATBOT
```
1. Patient message --> 2. chatbot_service --> 3. therapy_rag_service (RAG lookup) --> 4. AI_engine.data_interface (user context) --> 5. Enhanced prompt --> 6. LLM response --> 7. chatbot_messaging_service (store interaction) --> 8. Datawarehouse analytics
```

### D. AI GENERATES INSIGHTS
```
1. ai_analysis.analyze_user_data() --> 2. data_interface.get_ai_ready_dataset() --> 3. unified_data_collection_service.collect_comprehensive_user_data() --> 4. AI analysis with Ollama --> 5. UserAnalysis.create() --> 6. AIInsight.create()
```

### E. THERAPIST VIEWS ANALYTICS
```
1. Therapist dashboard --> 2. datawarehouse API --> 3. user_resume_service --> 4. AI-generated patient summary --> 5. therapy_analysis recommendations
```

## RAG System Workflow (Chatbot Knowledge)

### RAG Document Processing
```
1. setup_therapy_rag command --> 2. pdf_extractor --> 3. Document chunking --> 4. Embedding generation (Ollama) --> 5. vector_store (PostgreSQL pgvector) --> 6. therapy_rag_service ready
```

### RAG Query Processing  
```
1. User question --> 2. Query embedding --> 3. Vector similarity search --> 4. therapy_rag_service.get_therapy_approach() --> 5. CBT/DBT recommendation --> 6. Relevant therapy content --> 7. Context-enhanced response
```

## Crisis Detection Workflow
```
1. User message/journal --> 2. crisis_monitoring.py --> 3. NLP analysis --> 4. Risk scoring --> 5. Alert generation --> 6. Therapist notification --> 7. Intervention resources
```

## Data Quality & Performance Flow
```
1. Data collection --> 2. security_service (encryption) --> 3. audit_trail (compliance logging) --> 4. backup_recovery (data protection) --> 5. Quality scoring --> 6. Performance metrics
```

## Key Integration Points

### 1. Datawarehouse → AI Engine
- **Interface**: `AI_engine/services/data_interface.py`
- **Method**: `get_ai_ready_dataset(user_id, period_days)`
- **Data Flow**: Processed analytics → AI analysis → Insights

### 2. AI Engine → Chatbot  
- **Interface**: `chatbot/services/chatbot_service.py`
- **Method**: `_get_enhanced_ai_analysis(user)`
- **Data Flow**: User insights → Context enhancement → Personalized responses

### 3. Chatbot → Datawarehouse
- **Interface**: `datawarehouse/services/chatbot_messaging_service.py`
- **Method**: `collect_chatbot_data(user_id, days_back)`
- **Data Flow**: Conversation data → Analytics → Learning loop

### 4. RAG System → AI Enhancement
- **Interface**: `chatbot/services/rag/therapy_rag_service.py`
- **Method**: `get_therapy_approach(query, user_data)`
- **Data Flow**: Therapy knowledge + User context → Personalized therapy recommendations

## Real-Time Processing Pipeline

### Live Data Flow
```
1. User interaction --> 2. Django signals --> 3. realtime_analytics --> 4. Redis caching --> 5. WebSocket notifications --> 6. Dashboard updates
```

### Background Processing
```
1. Scheduled tasks --> 2. ETL pipeline --> 3. Batch analysis --> 4. Model updates --> 5. Performance optimization
```

## Security & Compliance Flow
```
1. Data collection --> 2. Encryption (AES-256) --> 3. Access control --> 4. Audit logging --> 5. HIPAA compliance --> 6. Backup encryption
```

## Machine Learning Pipeline
```
1. Raw data --> 2. Feature engineering --> 3. Model training (Ollama/Mistral) --> 4. Predictions --> 5. Interventions --> 6. Feedback loop
```

## API Endpoints Workflow

### Chatbot API
```
POST /chatbot/conversations/{id}/send_message/ --> chatbot_service --> RAG + AI analysis --> Response
```

### AI Analytics API  
```
GET /ai-engine/user-analysis/{user_id}/ --> ai_analysis.analyze_user_data() --> Comprehensive insights
```

### Datawarehouse API
```
GET /datawarehouse/user-snapshots/{user_id}/ --> unified_data_collection --> User analytics
```

## Error Handling & Resilience

### Graceful Degradation
```
1. Service failure --> 2. Fallback mechanisms --> 3. Cached data --> 4. Basic functionality --> 5. Error logging --> 6. Recovery procedures
```

### Data Quality Assurance
```
1. Data validation --> 2. Completeness checks --> 3. Quality scoring --> 4. Alert generation --> 5. Manual review triggers
```

## Performance Optimization

### Caching Strategy
```
1. Redis cache --> 2. Database optimization --> 3. Connection pooling --> 4. Query optimization --> 5. Load balancing
```

### Scalability Measures
```
1. Microservices architecture --> 2. Async processing --> 3. Distributed computing --> 4. Auto-scaling --> 5. Performance monitoring
```

## Summary of Complete System Flow

**For a typical user interaction:**

1. **User sends message** → Chatbot receives via Django REST API
2. **Context gathering** → Chatbot queries AI Engine for user insights
3. **AI data retrieval** → AI Engine fetches processed data from Datawarehouse
4. **RAG processing** → Therapy knowledge retrieved and therapy approach determined
5. **Enhanced prompt** → User context + therapy knowledge + conversation history
6. **LLM generation** → Ollama/Mistral generates personalized response
7. **Crisis detection** → Real-time analysis for risk assessment
8. **Response delivery** → Humanized, contextual therapeutic response
9. **Data storage** → Interaction stored back to Datawarehouse
10. **Analytics update** → Real-time analytics and learning loop
11. **Insights generation** → Background AI analysis for future interactions

This creates a continuous feedback loop where each interaction improves the system's understanding of the user and enhances future therapeutic support.
