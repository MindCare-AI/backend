# UserDataSnapshot Model - Comprehensive Explanation

## Overview
The `UserDataSnapshot` model is the central aggregation model in the MindCare datawarehouse that creates daily consolidated snapshots of user activity and mental health data. It serves as a pre-processed analytical layer that combines data from multiple sources into a single, queryable record per user per day.

## Purpose and Function
The UserDataSnapshot serves several critical purposes:

1. **Daily Data Aggregation**: Creates a single record per user per day containing summarized analytics
2. **Cross-Domain Analysis**: Combines data from mood tracking, journaling, messaging, social feeds, and app usage
3. **Risk Assessment**: Provides risk indicators and attention flags for crisis monitoring
4. **Performance Optimization**: Pre-calculated metrics reduce query complexity for dashboards and reports
5. **AI Engine Integration**: Provides structured, analysis-ready data for machine learning models
6. **Therapist Dashboard**: Powers therapist analytics and patient monitoring interfaces

## Model Structure

### Core Identification
```python
user = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.CASCADE)
snapshot_date = models.DateField()
```
- **User Reference**: Links to the CustomUser model
- **Snapshot Date**: Date of the data snapshot (unique per user per day)
- **Unique Constraint**: One snapshot per user per day

### Mood Analytics Section
```python
mood_entries_count = models.IntegerField(default=0)
avg_mood_score = models.FloatField(null=True)
mood_volatility = models.FloatField(null=True)  # Standard deviation
dominant_mood = models.CharField(max_length=50, null=True)
mood_trend = models.CharField(max_length=20, choices=[...], null=True)
```

**Fields Explained:**
- `mood_entries_count`: Number of mood logs created on this date
- `avg_mood_score`: Average mood rating (typically 1-10 scale)
- `mood_volatility`: Standard deviation of mood scores (measures mood stability)
- `dominant_mood`: Most frequently reported mood category
- `mood_trend`: Calculated trend (improving/declining/stable/volatile)

### Journal Analytics Section
```python
journal_entries_count = models.IntegerField(default=0)
avg_journal_length = models.FloatField(null=True)  # Average entry length
total_words_written = models.IntegerField(default=0)
avg_sentiment_score = models.FloatField(null=True)
writing_consistency_score = models.FloatField(null=True)
journal_topics = ArrayField(models.CharField(max_length=100), default=list)
```

**Fields Explained:**
- `journal_entries_count`: Number of journal entries created
- `avg_journal_length`: Average character/word count per entry
- `total_words_written`: Total word count across all entries
- `avg_sentiment_score`: Average sentiment analysis score (-1 to 1)
- `writing_consistency_score`: Measure of writing pattern consistency
- `journal_topics`: List of detected topics/themes in journal entries

### Communication Analytics Section
```python
messages_sent = models.IntegerField(default=0)
messages_received = models.IntegerField(default=0)
avg_response_time_minutes = models.FloatField(null=True)
communication_sentiment = models.FloatField(null=True)
```

**Fields Explained:**
- `messages_sent/received`: Counts of messaging activity
- `avg_response_time_minutes`: Average time to respond to messages
- `communication_sentiment`: Overall sentiment of communications

### Activity Analytics Section
```python
app_sessions_count = models.IntegerField(default=0)
total_session_duration_minutes = models.IntegerField(default=0)
features_used = ArrayField(models.CharField(max_length=50), default=list)
```

**Fields Explained:**
- `app_sessions_count`: Number of app sessions/logins
- `total_session_duration_minutes`: Total time spent in app
- `features_used`: List of app features accessed

### Social Analytics Section (Feeds)
```python
posts_created = models.IntegerField(default=0)
comments_made = models.IntegerField(default=0)
likes_given = models.IntegerField(default=0)
likes_received = models.IntegerField(default=0)
social_engagement_score = models.FloatField(null=True)
```

**Fields Explained:**
- `posts_created`: Number of posts created in social feeds
- `comments_made`: Number of comments posted
- `likes_given/received`: Social interaction metrics
- `social_engagement_score`: Calculated engagement score (0-1)

### Risk Indicators Section
```python
crisis_indicators_count = models.IntegerField(default=0)
risk_score = models.FloatField(null=True)  # 0-1 scale
needs_attention = models.BooleanField(default=False)
```

**Critical Fields:**
- `crisis_indicators_count`: Number of crisis-related indicators detected
- `risk_score`: Calculated risk assessment (0=low risk, 1=high risk)
- `needs_attention`: Boolean flag for immediate therapist attention

### Metadata Section
```python
data_completeness_score = models.FloatField(default=1.0)
data_quality_score = models.FloatField(default=1.0)
last_updated = models.DateTimeField(null=True, blank=True)
created_at = models.DateTimeField(auto_now_add=True)
updated_at = models.DateTimeField(auto_now=True)
```

**Quality Tracking:**
- `data_completeness_score`: Percentage of expected data fields populated
- `data_quality_score`: Overall data quality assessment
- `last_updated`: When snapshot was last recalculated
- Standard Django timestamps for creation and updates

## Data Collection Workflow

### 1. ETL Pipeline Integration
The UserDataSnapshot is populated through the ETL (Extract, Transform, Load) pipeline:

```python
# From etl_service_clean.py
def _create_user_snapshot(self, user, transformed_data):
    snapshot, created = UserDataSnapshot.objects.get_or_create(
        user=user, snapshot_date=snapshot_date, defaults={}
    )
    # Update fields with transformed data
    if "avg_mood_score" in row and pd.notna(row["avg_mood_score"]):
        snapshot.avg_mood_score = float(row["avg_mood_score"])
```

### 2. Data Collection Services
Multiple specialized services contribute data:
- **MoodTrackingService**: Provides mood analytics
- **JournalingService**: Provides writing and sentiment analytics
- **FeedsService**: Provides social interaction analytics
- **TherapistSessionService**: Provides therapy-related metrics
- **UnifiedDataCollectionService**: Orchestrates all services

### 3. Real-time Updates
Snapshots can be updated throughout the day as new data arrives:
- Incremental updates via ETL service
- Real-time analytics processing
- Batch processing for complex calculations

## Usage in the System

### 1. Risk Monitoring Dashboard
```python
# From views.py
high_risk_users = queryset.filter(needs_attention=True).values("user").distinct().count()
avg_risk_score = queryset.aggregate(avg_risk=Avg("risk_score"))["avg_risk"]
```

### 2. User Trend Analysis
```python
# From views.py - user_trends endpoint
snapshots = UserDataSnapshot.objects.filter(
    user_id=user_id, 
    snapshot_date__gte=start_date, 
    snapshot_date__lte=end_date
).order_by("snapshot_date")
```

### 3. AI Engine Integration
The AI engine uses UserDataSnapshot as a primary data source for:
- Mood prediction models
- Risk assessment algorithms
- Therapy recommendation systems
- Behavioral pattern analysis

### 4. Therapist Analytics
Therapists access aggregated patient data through:
- Patient progress dashboards
- Risk alert systems
- Treatment effectiveness tracking
- Communication pattern analysis

## Database Optimization

### Indexes
```python
indexes = [
    models.Index(fields=["user", "-snapshot_date"]),
    models.Index(fields=["snapshot_date"]),
    models.Index(fields=["risk_score"]),
    models.Index(fields=["needs_attention"]),
]
```

### Constraints
- **Unique Together**: One snapshot per user per day
- **Ordering**: Newest snapshots first
- **Foreign Key**: Cascading delete with user

## Integration Points

### 1. Crisis Monitoring System
```python
# Risk indicators feed into crisis detection
if snapshot.risk_score > 0.7 or snapshot.needs_attention:
    trigger_crisis_alert(user, snapshot)
```

### 2. AI Analytics Pipeline
```python
# Snapshots provide AI-ready datasets
ai_dataset = AIAnalysisDataset.objects.create(
    user=user,
    mood_summary=snapshot.mood_data,
    behavioral_patterns=snapshot.activity_data
)
```

### 3. Backup and Recovery
UserDataSnapshot records are included in:
- Daily automated backups
- Data export functionality
- GDPR compliance data extraction
- Data retention policies

## Data Quality and Validation

### Quality Scores
- **Completeness Score**: Measures how many expected fields have data
- **Quality Score**: Assesses data accuracy and consistency
- **Validation Rules**: Ensures data integrity across updates

### Error Handling
```python
# From data collection services
try:
    results[f"{data_type}_data"] = future.result()
except Exception as exc:
    logger.error(f"Error collecting {data_type} data", error=str(exc))
    errors.append(f"{data_type}: {str(exc)}")
    results[f"{data_type}_data"] = {}
```

## Security and Privacy

### Data Protection
- **Field-level Encryption**: Sensitive data encrypted at rest
- **Access Controls**: Therapist-patient data boundaries
- **Audit Trails**: All access and modifications logged
- **GDPR Compliance**: Data export and deletion capabilities

### Privacy Considerations
- Personal data aggregated and anonymized where possible
- Sensitive content filtered through privacy layers
- User consent tracked for data processing
- Data retention policies enforced

## Crisis Monitoring Workflow - Suicide Ideation Detection

### Scenario: Patient Types "I want to kill myself" in Chatbot

**Complete Workflow with --> arrows:**

```
Patient --> Chatbot Message: "I want to kill myself"
    |
    v
Chatbot Service --> Crisis Detection Keywords Analysis
    |
    v
Crisis Keywords Detected --> Crisis Monitoring Service
    |
    v
Crisis Monitoring Service --> Risk Level Assessment
    |
    v
Risk Level: CRITICAL (0.95) --> Immediate Response Pipeline
    |
    v
Immediate Response Pipeline --> Multiple Actions (Parallel):
    |
    ├── Emergency Resources --> Patient (Immediate)
    |   └── "Crisis support resources, helpline numbers"
    |
    ├── Therapist Alert --> Therapist Dashboard
    |   └── "URGENT: Patient expressing suicidal ideation"
    |
    ├── Admin Notification --> Admin Panel
    |   └── "Crisis event logged - requires review"
    |
    └── Data Logging --> Crisis Event Database
        └── "Log crisis details, timestamp, response actions"
    |
    v
UserDataSnapshot Update --> Risk Indicators Section:
    |
    ├── crisis_indicators_count: +1
    ├── risk_score: 0.95
    └── needs_attention: True
    |
    v
AI Engine Integration --> Enhanced Monitoring
    |
    ├── Therapy Analysis Service --> Emergency Session Plan
    ├── Predictive Service --> High-Risk Monitoring
    └── Social Analysis --> Support Network Alert
    |
    v
Follow-up Actions:
    |
    ├── Chatbot --> Gentle Support Response
    ├── Therapist --> Priority Scheduling
    └── System --> Continuous Monitoring (24-48 hours)
```

### Detailed Step-by-Step Process:

**1. Initial Detection (Chatbot Layer)**
```
Patient Input: "I want to kill myself"
    |
    v
Chatbot NLP Analysis --> Crisis Keywords Detected:
    - "kill myself" (High severity)
    - "want to" (Intent indicator)
    - Confidence Score: 0.98
```

**2. Crisis Monitoring Service Activation**
```
Crisis Keywords --> CrisisMonitoringService.detect_crisis()
    |
    v
Risk Assessment Algorithm:
    - Keyword severity: HIGH
    - User context: Depression history
    - Recent mood trend: Declining
    - Final Risk Score: 0.95 (CRITICAL)
```

**3. Immediate Response (< 30 seconds)**
```
CRITICAL Risk --> Emergency Protocol:
    |
    ├── Patient Response:
    |   └── "I'm concerned about what you've shared. 
    |       You're not alone. Here are immediate resources:
    |       🆘 Crisis Hotline: 988
    |       🏥 Emergency Services: 911"
    |
    ├── Therapist Alert:
    |   └── "🚨 URGENT: [Patient Name] expressing suicidal ideation
    |       Time: [timestamp]
    |       Message: [safe excerpt]
    |       Action Required: Immediate contact"
    |
    └── System Logging:
        └── CrisisEvent.objects.create(
            user=patient,
            crisis_type="suicidal_ideation",
            severity="critical",
            trigger_message="[encrypted]",
            response_actions=["resources_provided", "therapist_alerted"]
        )
```

**4. Datawarehouse Integration (UserDataSnapshot)**
```
Crisis Event --> Datawarehouse Real-time Update:
    |
    v
RealTimeAnalyticsService.process_event({
    "event_type": "crisis_detected",
    "user_id": patient.id,
    "crisis_data": {...}
})
    |
    v
UnifiedDataCollectionService.update_snapshot_immediate(
    user=patient,
    crisis_event={
        "crisis_indicators_count": +1,
        "risk_score": 0.95,
        "needs_attention": True
    }
)
    |
    v
UserDataSnapshot.objects.get_or_create(
    user=patient, 
    snapshot_date=today
)
    |
    v
Datawarehouse Fields Updated:
    - crisis_indicators_count: 1
    - risk_score: 0.95
    - needs_attention: True
    - last_updated: current_timestamp
    - communication_sentiment: -0.9 (crisis message)
    - features_used: ["chatbot", "crisis_support"]
```

**5. AI Engine + Datawarehouse Response Chain**
```
High Risk Snapshot --> AI Services via Data Interface:
    |
    ├── Crisis Monitoring Service:
    |   └── unified_data_collector.collect_crisis_context(patient, 48_hours)
    |   └── continuous_monitoring(patient, duration=48_hours)
    |
    ├── Therapy Analysis Service:
    |   └── datawarehouse.get_ai_ready_dataset(patient.id, crisis_analysis=True)
    |   └── emergency_session_plan = {
    |       "focus_areas": ["crisis_intervention", "safety_planning"],
    |       "session_goals": ["assess_immediate_risk", "develop_coping_strategies"],
    |       "requires_immediate_attention": True,
    |       "recommended_timeframe": "within_4_hours"
    |   }
    |
    ├── Predictive Service:
    |   └── datawarehouse.analyze_crisis_patterns(patient, historical=True)
    |   └── high_risk_monitoring = {
    |       "prediction": "requires_intensive_support", 
    |       "monitoring_frequency": "hourly",
    |       "risk_factors": ["suicidal_ideation", "mood_decline"]
    |   }
    |
    └── Social Analysis Service:
        └── datawarehouse.get_social_analytics(patient.id)
        └── support_network_analysis = {
            "emergency_contacts": ["therapist", "family_member"],
            "social_isolation_risk": "high",
            "recommended_actions": ["increase_social_support"]
        }
```

**6. Datawarehouse-Powered Follow-up (Next 24-48 hours)**
```
Crisis Snapshot in Datawarehouse --> Continuous Analytics:
    |
    ├── Chatbot Behavior (Data-Driven):
    |   ├── ETLService.update_real_time(patient, "crisis_mode")
    |   ├── Datawarehouse tracks: message_sentiment, response_patterns
    |   ├── Increased empathy responses based on risk_score
    |   ├── Regular check-ins every 2 hours
    |   └── Crisis resource reminders
    |
    ├── Therapist Dashboard (Datawarehouse Queries):
    |   ├── Patient flagged as "HIGH PRIORITY" (needs_attention=True)
    |   ├── Crisis timeline from UserDataSnapshot history
    |   ├── Risk trend analysis from datawarehouse
    |   └── Emergency session scheduling priority
    |
    ├── System Monitoring (Real-time Analytics):
    |   ├── RealTimeAnalyticsService.monitor_crisis_user(patient.id)
    |   ├── All messages → UserDataSnapshot.communication_sentiment
    |   ├── Mood logs → immediate datawarehouse updates
    |   └── Risk score recalculated hourly via ETL
    |
    └── Data Collection Enhancement:
        ├── UnifiedDataCollectionService.crisis_mode(patient.id)
        ├── Enhanced UserDataSnapshot updates (hourly vs daily)
        ├── Crisis recovery tracking in datawarehouse
        └── Intervention effectiveness → therapy analytics
```

### Technical Implementation Details:

**Crisis Detection Algorithm:**
```python
def detect_crisis_in_message(message_text):
    crisis_keywords = {
        "critical": ["kill myself", "end my life", "suicide", "don't want to live"],
        "high": ["hurt myself", "harm myself", "can't go on"],
        "medium": ["give up", "no point", "hopeless"]
    }
    
    for severity, keywords in crisis_keywords.items():
        for keyword in keywords:
            if keyword in message_text.lower():
                return {
                    "crisis_detected": True,
                    "severity": severity,
                    "confidence": calculate_confidence(message_text, keyword),
                    "keyword_matched": keyword
                }
    return {"crisis_detected": False}
```

**Real-time Alert System:**
```python
def trigger_crisis_alert(user, crisis_data):
    # Immediate patient response
    send_crisis_resources(user)
    
    # Therapist notification
    notify_therapist(user, crisis_data, priority="URGENT")
    
    # Update snapshot
    update_user_snapshot(user, crisis_indicators_count=1, risk_score=0.95)
    
    # Start monitoring
    start_enhanced_monitoring(user, duration_hours=48)
```

This workflow ensures immediate response while maintaining comprehensive data tracking for ongoing care and analysis.

## Summary

UserDataSnapshot is the cornerstone of the MindCare datawarehouse, providing:

1. **Centralized Data Aggregation**: One place for all user activity metrics
2. **Performance Optimization**: Pre-calculated analytics for fast queries
3. **Risk Assessment**: Real-time crisis monitoring capabilities
4. **AI Integration**: Structured data for machine learning models
5. **Clinical Decision Support**: Analytics for therapist decision-making
6. **Quality Assurance**: Data completeness and accuracy tracking

This model enables the MindCare platform to provide sophisticated mental health analytics while maintaining performance, security, and clinical utility.

## Conclusion: What the AI Engine Uses Insights For

## AI Engine Insights Usage - Comprehensive Conclusion

### What the AI Engine Uses Insights For

The AI engine in MindCare leverages insights from the UserDataSnapshot and other data sources to power intelligent mental health support across multiple domains. Here's what the AI engine accomplishes with these insights:

### 1. **Risk Assessment and Crisis Prevention**
**Purpose**: Early detection and prevention of mental health crises
- **Real-time Risk Scoring**: Uses mood volatility, sentiment analysis, and behavioral patterns to calculate risk scores (0-1 scale)
- **Crisis Prediction**: Identifies users likely to experience crisis episodes 24-72 hours in advance
- **Intervention Timing**: Determines optimal moments for therapeutic interventions
- **Escalation Protocols**: Triggers appropriate response levels based on risk severity

**Example Insight Usage**:
```
Insight: "User shows 40% increase in negative sentiment + 60% decrease in social engagement"
AI Engine Action: Risk score increased to 0.75, therapist alerted, enhanced monitoring activated
```

### 2. **Personalized Therapy Recommendations**
**Purpose**: Optimize therapeutic approaches for individual patients
- **Treatment Personalization**: Matches therapy techniques to user personality and response patterns
- **Session Planning**: Suggests focus areas for upcoming therapy sessions
- **Homework Assignments**: Recommends specific therapeutic exercises based on user progress
- **Intervention Effectiveness**: Tracks which therapeutic approaches work best for each user

**Example Insight Usage**:
Insight: "User responds well to CBT techniques but struggles with mindfulness exercises"
AI Engine Action: Therapy plan adjusted to emphasize cognitive behavioral techniques
```

### 3. **Behavioral Pattern Recognition**
**Purpose**: Identify meaningful patterns in user behavior and mental health
- **Mood Cycle Detection**: Identifies patterns in mood fluctuations and triggers
- **Activity Correlation**: Links specific activities to mood improvements or declines
- **Communication Patterns**: Analyzes messaging frequency and sentiment trends
- **Routine Optimization**: Suggests lifestyle changes based on behavioral insights

**Example Insight Usage**:
```
Insight: "User's mood improves 30% on days with >60 minutes app usage + journaling"
AI Engine Action: Recommends daily journaling and guided app activities
```

### 4. **Predictive Analytics for Mental Health**
**Purpose**: Forecast future mental health states and needs
- **Mood Prediction**: Predicts likely mood states 1-7 days in advance
- **Relapse Prevention**: Identifies early warning signs of depression/anxiety episodes
- **Recovery Trajectory**: Estimates treatment timeline and milestones
- **Resource Planning**: Predicts when users will need additional support

**Example Insight Usage**:
```
Insight: "User showing early relapse indicators - 70% probability of mood decline next week"
AI Engine Action: Proactive therapy session scheduled, coping strategies recommended
```

### 5. **Clinical Decision Support**
**Purpose**: Assist therapists with data-driven treatment decisions
- **Treatment Efficacy**: Measures effectiveness of different therapeutic interventions
- **Progress Tracking**: Provides objective measures of patient improvement
- **Red Flag Detection**: Alerts therapists to concerning behavioral changes
- **Care Coordination**: Suggests when to involve other healthcare providers

**Example Insight Usage**:
```
Insight: "Patient shows 25% mood improvement but increased isolation behaviors"
AI Engine Action: Recommends social skills therapy component, family involvement
```

### 6. **User Experience Personalization**
**Purpose**: Customize the app experience for each user's needs and preferences
- **Content Curation**: Selects relevant articles, exercises, and resources
- **Feature Recommendations**: Suggests app features that align with user goals
- **Interaction Timing**: Optimizes when to send notifications and prompts
- **Interface Adaptation**: Adjusts app complexity based on user engagement patterns

**Example Insight Usage**:
```
Insight: "User engages most with visual content during evening hours"
AI Engine Action: Prioritizes infographics and videos in evening notifications
```

### 7. **System-Wide Intelligence and Learning**
**Purpose**: Improve the overall platform through aggregate insights
- **Population Health**: Identifies trends across user populations
- **Feature Development**: Guides development of new platform features
- **Algorithm Improvement**: Continuously refines AI models based on outcomes
- **Research Insights**: Generates anonymized insights for mental health research

**Example Insight Usage**:
```
Insight: "85% of users with anxiety benefit from specific breathing exercises"
AI Engine Action: Breathing exercises promoted system-wide for anxiety users
```

### Data Flow for AI Insights Generation

```
Raw User Data (Multiple Sources)
    |
    v
UserDataSnapshot (Daily Aggregation)
    |
    v
AI Analysis Services (Processing)
    |
    ├── Crisis Monitoring → Risk Assessment
    ├── Therapy Analysis → Treatment Recommendations  
    ├── Predictive Service → Future State Predictions
    ├── Social Analysis → Relationship Insights
    └── Data Interface → Unified AI Dataset
    |
    v
Generated Insights (Actionable Intelligence)
    |
    v
Application Layer (User-Facing)
    |
    ├── Patient Experience → Personalized recommendations
    ├── Therapist Dashboard → Clinical decision support
    ├── Crisis Alerts → Immediate interventions
    └── System Optimization → Platform improvements
```

### Value Delivered Through AI Insights

**For Patients**:
- Personalized mental health support
- Early crisis intervention
- Optimized therapy experiences
- Proactive care recommendations

**For Therapists**:
- Data-driven treatment decisions
- Early warning systems
- Progress tracking tools
- Efficient care coordination

**For the Platform**:
- Continuous improvement through learning
- Evidence-based feature development
- Population health insights
- Research contribution capabilities

**For Healthcare Outcomes**:
- Reduced crisis incidents
- Improved treatment effectiveness
- Better patient engagement
- Enhanced care quality

### Technical Architecture for Insights

The AI engine uses insights through a sophisticated architecture:

1. **Data Collection Layer**: UserDataSnapshot + real-time streams
2. **Analytics Processing**: Multiple AI services working in parallel
3. **Insight Generation**: Machine learning models producing actionable intelligence
4. **Application Layer**: Insights delivered to users, therapists, and system components
5. **Feedback Loop**: Outcomes tracked to improve future insights

